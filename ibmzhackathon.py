# -*- coding: utf-8 -*-
"""IBMZHackathon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lt0EefIcbfb3NrNBbfnRLl6SBX1FI0Ur
"""

from google.colab import files
files.upload()  # Upload the kaggle.json file here

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d birdy654/cifake-real-and-ai-generated-synthetic-images

!unzip -q cifake-real-and-ai-generated-synthetic-images.zip -d data

from torchvision import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader

transform = transforms.Compose([
    transforms.Resize((224,224)),   # Resize images to 224x224
    transforms.ToTensor(),           # Convert to Tensor
    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])  # Normalize
])

from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split

transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])
])

full_train_dataset = datasets.ImageFolder('data/train', transform=transform)

train_size = int(0.8 * len(full_train_dataset))
val_size = len(full_train_dataset) - train_size

train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])

test_dataset = datasets.ImageFolder('data/test', transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

print("Train images:", len(train_dataset))
print("Validation images:", len(val_dataset))
print("Test images:", len(test_dataset))

import torch
import torch.nn as nn
import torch.optim as optim
import timm  # For pre-trained models

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Using device:", device)

model = timm.create_model('resnet18', pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 2)  # 2 classes
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

epochs = 5  # You can increase later
for epoch in range(epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    # Validation
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f"Epoch {epoch+1}/{epochs} | Loss: {running_loss/len(train_loader):.4f} | Val Accuracy: {100*correct/total:.2f}%")

model.eval()
correct, total = 0, 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Test Accuracy: {100*correct/total:.2f}%")

torch.save(model.state_dict(), 'ai_image_detector.pth')

from google.colab import drive
drive.mount('/content/drive')

!pwd
!ls

!cp /content/ai_image_detector.pth /content/drive/MyDrive/

"""LOAD MODEL >>>"""

import torch
from torchvision import models, transforms
from PIL import Image

model = timm.create_model('resnet18', pretrained=False) # Changed from resnet50 to resnet18
model.fc = torch.nn.Linear(model.fc.in_features, 2)  # 2 classes: real / ai

# Load the trained weights
model.load_state_dict(torch.load('/content/drive/MyDrive/ai_image_detector.pth', map_location='cpu'))
model.eval()

print("✅ Model loaded successfully!")

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# Example: your uploaded test image
image_path = '/content/drive/MyDrive/data/NewTestDataIBM/download.jpg'  # change this path

img = Image.open(image_path).convert('RGB')
input_tensor = transform(img).unsqueeze(0)  # shape: [1, 3, 224, 224]

# Class labels — update if yours are different
classes = ['real', 'ai_generated']

# Ensure device is defined and consistent
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device) # Ensure the model is on the correct device

# Move the input tensor to the same device as the model
input_tensor = input_tensor.to(device)

with torch.no_grad():
    output = model(input_tensor)
    _, predicted = torch.max(output, 1)

print(f"Predicted raw value: {predicted.item()}") # Added for debugging

# Check if the predicted value is within the range of class indices
if 0 <= predicted.item() < len(classes):
    print(f"Prediction: {classes[predicted.item()]}")
else:
    print(f"Error: Predicted value {predicted.item()} is out of range for classes with indices 0 to {len(classes)-1}.")

"""ResNET"""

import torch
from torchvision import datasets, transforms
from sklearn.metrics import classification_report
from torch.utils.data import DataLoader

transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

test_data = datasets.ImageFolder('/content/data/test', transform=transform)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

# Assuming 'timm' is imported (as in cell 6C3dvpR03Pjj)
import timm
import torch

# Use timm.create_model to match the training setup
model = timm.create_model('resnet18', pretrained=False)
# Modify the final fully connected layer for 2 output classes
model.fc = torch.nn.Linear(model.fc.in_features, 2)

# Load the trained weights
model.load_state_dict(torch.load('/content/drive/MyDrive/ai_image_detector.pth', map_location='cpu'))
model.eval()

import torch
from tqdm.notebook import tqdm  # shows a nice progress bar

y_true = []
y_pred = []

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

model.eval()

with torch.no_grad():
    for images, labels in tqdm(test_loader, desc="Evaluating", unit="batch"):
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

print("✅ Evaluation complete!")

print(classification_report(y_true, y_pred, target_names=['real', 'ai_generated']))

from PIL import Image # Import the Image class

img_path = '/content/1_LqClB-Wa__W9WrNqP74I3Q.png'  # replace with your uploaded file
img = Image.open(img_path).convert('RGB')
input_tensor = transform(img).unsqueeze(0)

# Assuming 'model' and 'transform' are already defined and available
# Ensure device is defined and consistent
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device) # Ensure the model is on the correct device
input_tensor = input_tensor.to(device) # Move the input tensor to the same device as the model

# Class labels - update if yours are different
classes = ['real', 'ai_generated']


with torch.no_grad():
    output = model(input_tensor)
    _, predicted = torch.max(output, 1)

print(f"Prediction: {classes[predicted.item()]}")

"""BitMind + Trained Model"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile hybrid_ai_detector.py

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import requests
import io

BITMIND_URL = "https://api.bitmind.ai/oracle/v1/34/detect-image"
BITMIND_KEY = "oracle-dc220854-d6f1-4282-92d6-55d4f9fac521:64b25953"  # your given token
MODEL_PATH = "/content/drive/MyDrive/ai_image_detector.pth"

W_API = 0.5   # BitMind weight
W_MODEL = 0.5  # Your model weight
THRESHOLD = 0.5

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import requests
import io
import timm # Import timm for model creation

class AIImageDetector(nn.Module):
    def __init__(self):
        super(AIImageDetector, self).__init__()
        # Instantiate the model architecture
        self.model = timm.create_model('resnet18', pretrained=False)
        self.model.fc = torch.nn.Linear(self.model.fc.in_features, 2) # Modify for 2 output classes

        # Load the state dictionary into the model
        state_dict = torch.load(MODEL_PATH, map_location=device)
        self.model.load_state_dict(state_dict)

        self.model.eval() # Now it's safe to call eval() on the model object

    def predict(self, image):
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        img_tensor = transform(image).unsqueeze(0).to(device)
        with torch.no_grad():
            output = self.model(img_tensor)
            # Assuming the output is logits, apply sigmoid to get a probability for one of the classes
            # For binary classification with CrossEntropyLoss during training, the output is typically logits.
            # Sigmoid converts logits to a probability between 0 and 1.
            # Let's assume the probability of being 'ai_generated' is the second element (index 1) after softmax, or apply sigmoid to the output of the AI class logit
            # A common approach for binary classification with CrossEntropyLoss is to interpret the output directly as logits for two classes.
            # To get a single probability of being AI-generated, you can use softmax and take the probability of the 'ai_generated' class (assuming it's index 1).
            # Or, if your model's final layer was a single output for the probability of being AI, you'd use sigmoid.
            # Given the training with CrossEntropyLoss and 2 output features, the output is likely logits.
            # We can take the logit for the 'ai_generated' class (assuming index 1) and apply sigmoid to get a probability.
            prob = torch.sigmoid(output[:, 1]).item() # Get the logit for the second class and apply sigmoid

        return prob

model = AIImageDetector()

def call_bitmind_api(image_bytes):
    headers = {"Authorization": f"Bearer {BITMIND_KEY}"}
    # Use a more specific filename and content type
    files = {"image": ("image.jpg", image_bytes, "image/jpeg")}
    resp = requests.post(BITMIND_URL, headers=headers, files=files)

    # Check for HTTP errors and print response content for debugging
    try:
        resp.raise_for_status()
    except requests.exceptions.HTTPError as e:
        print(f"HTTP Error: {e}")
        print("API Response Content:")
        print(resp.text) # Print the response body
        raise # Re-raise the exception after printing

    data = resp.json()
    # Be more explicit about accessing the score/confidence
    score_api = data.get("confidence", data.get("score", 0.5)) # Use get with a default
    return float(score_api), data

def get_weighted_result(image_path):
    with open(image_path, "rb") as f:
        image_bytes = f.read()
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

    # Get model and API confidences
    score_model = model.predict(image)
    score_api, api_resp = call_bitmind_api(image_bytes)

    # Weighted mean
    weighted_mean = ((W_API * score_api) + (W_MODEL * score_model)) / (W_API + W_MODEL)

    # Final decision
    prediction = "AI-generated" if weighted_mean >= THRESHOLD else "Real"

    return {
        "score_api": round(score_api, 4),
        "score_model": round(score_model, 4),
        "weighted_mean": round(weighted_mean, 4),
        "result": prediction
    }

if __name__ == "__main__":
    test_image = "/content/premium_photo-1664474619075-644dd191935f.jpg"  # raw string
    result = get_weighted_result(str(test_image))
    print(result)

from google.colab import files
files.download("hybrid_ai_detector.py")

torch.save(model, "/content/drive/MyDrive/hybrid_bitmind_model.pth")

print("✅ Hybrid model saved as /content/drive/MyDrive/hybrid_bitmind_model.pth")